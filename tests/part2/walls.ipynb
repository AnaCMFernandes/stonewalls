{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Identifying stonewalls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.ml_utils'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-71d642923c0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myellow_follow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lib.ml_utils'"
     ]
    }
   ],
   "source": [
    "# Local path, change this.\n",
    "yellow_follow = 'C:/Users/EZRA/Documents/yellow/lib/'\n",
    "\n",
    "import sys; sys.path.append(yellow_follow) \n",
    "import pandas as pd\n",
    "import ml_utils\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Dropout, Conv2D, MaxPooling2D, Flatten, Conv2DTranspose, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "folder = r\"C:\\Users\\EZRA\\OneDrive - NIRAS\\thesis\\Data\\training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = np.load(folder + \"dtm.npy\")\n",
    "walls = np.load(folder + \"walls.npy\")\n",
    "meta = pd.read_csv(folder + \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls = (walls == 1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = np.swapaxes(meta[meta[\"land\"] == 1].values, 0, 1)[0]\n",
    "wall_mask = np.swapaxes(meta[meta[\"wall\"] == 1].values, 0, 1)[0]    # Has a wall\n",
    "no_wall_mask = np.swapaxes(meta[meta[\"wall\"] == 2].values, 0, 1)[0] # Has _no_ wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(715,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "no_wall_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(599,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "wall_mask.shape"
   ]
  },
  {
   "source": [
    "Regression first"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate([dtm[wall_mask], dtm[no_wall_mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.concatenate([meta.values[wall_mask], meta.values[no_wall_mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1314, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "truth = (np.swapaxes(truth, 0, 1)[2] == 1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5256, 64, 64)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "train = ml_utils.add_rotations(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.concatenate([truth, truth, truth, truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "shuffle_mask = np.random.permutation(len(truth))\n",
    "train = train[shuffle_mask]\n",
    "truth = truth[shuffle_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, truth, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(shape, name, activation='relu', kernel_initializer='normal', maxnorm=4, sizes=[64, 96, 128]):\n",
    "    model_input = Input(shape=shape, name=name)\n",
    "    model = Conv2D(sizes[0],\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_constraint=max_norm(maxnorm),\n",
    "        bias_constraint=max_norm(maxnorm),\n",
    "    )(model_input)\n",
    "    model = BatchNormalization()(model)\n",
    "\n",
    "    model = Conv2D(sizes[1],\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_constraint=max_norm(maxnorm),\n",
    "        bias_constraint=max_norm(maxnorm),\n",
    "    )(model)\n",
    "    model = BatchNormalization()(model)\n",
    "\n",
    "    model = Conv2D(sizes[2],\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_constraint=max_norm(maxnorm),\n",
    "        bias_constraint=max_norm(maxnorm),\n",
    "    )(model)\n",
    "    model = BatchNormalization()(model)\n",
    "\n",
    "    # Switch this to regression\n",
    "    output = Conv2D(1, kernel_size=3, padding='same', activation='relu', kernel_initializer=kernel_initializer)(model)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=output)\n",
    "\n",
    "lr = 0.001\n",
    "bs = 512\n",
    "epochs = 50\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = lr\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "model = define_model(X_train.shape[1:], \"Generative\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "        learning_rate=lr,\n",
    "        name=\"Adam\",\n",
    "    ),\n",
    "    loss='log_cosh',\n",
    "    metrics=[\n",
    "        'mse',\n",
    "        'mae',\n",
    "        'log_cosh',\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    verbose=0,\n",
    "    batch_size=bs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        LearningRateScheduler(step_decay),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=10,\n",
    "            min_delta=0.1,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Batch_size: {str(bs)}\")\n",
    "loss, mse, mae, log_cosh = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Mean Square Error:      {round(mse, 3)}\")\n",
    "print(f\"Mean Absolute Error:    {round(mae, 3)}\")\n",
    "print(f\"log_cosh:               {round(log_cosh, 3)}\")\n",
    "print(\"\")\n",
    "\n",
    "import pdb; pdb.set_trace()"
   ]
  }
 ]
}